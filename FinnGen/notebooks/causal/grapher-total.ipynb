{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8135f00d-05d2-4652-a01d-c47e77855f44",
   "metadata": {},
   "source": [
    "# Predicting Causal SNPs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892cd773-aa1b-4e88-a2f5-b0e763aebdcd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c81768a-68f0-4a35-8903-ed78915e978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can get rid of whatever libraries you dont need\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from numba import jit, prange\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder, StandardScaler, OrdinalEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.utils import to_undirected, negative_sampling\n",
    "import networkx as nx\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.special import expit\n",
    "from typing import List, Dict\n",
    "import time\n",
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "import category_encoders as ce\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import copy\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "# Print versions of imported libraries\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Torch Geometric version: {torch_geometric.__version__}\")\n",
    "print(f\"NetworkX version: {nx.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # Current CUDA device\n",
    "    print(f\"Using {torch.cuda.get_device_name()} ({device})\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37229f32-0837-44e6-9f56-ebaeb33539c6",
   "metadata": {},
   "source": [
    "## All Chroms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c3c73c5-83a4-4af9-b5b2-4296e579109c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t\t<script type=\"text/javascript\">\n",
       "\t\t\t<!--\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_script');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('script');\n",
       "\t\t\t\telement.type = 'text/javascript';\n",
       "\t\t\t\telement.innerHTML = 'function NetworKit_pageEmbed(id) { var i, j; var elements; elements = document.getElementById(id).getElementsByClassName(\"Plot\"); for (i=0; i<elements.length; i++) { elements[i].id = id + \"_Plot_\" + i; var data = elements[i].getAttribute(\"data-image\").split(\"|\"); elements[i].removeAttribute(\"data-image\"); var content = \"<div class=\\\\\"Image\\\\\" id=\\\\\"\" + elements[i].id + \"_Image\\\\\" />\"; elements[i].innerHTML = content; elements[i].setAttribute(\"data-image-index\", 0); elements[i].setAttribute(\"data-image-length\", data.length); for (j=0; j<data.length; j++) { elements[i].setAttribute(\"data-image-\" + j, data[j]); } NetworKit_plotUpdate(elements[i]); elements[i].onclick = function (e) { NetworKit_overlayShow((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"HeatCell\"); for (i=0; i<elements.length; i++) { var data = parseFloat(elements[i].getAttribute(\"data-heat\")); var color = \"#00FF00\"; if (data <= 1 && data > 0) { color = \"hsla(0, 100%, 75%, \" + (data) + \")\"; } else if (data <= 0 && data >= -1) { color = \"hsla(240, 100%, 75%, \" + (-data) + \")\"; } elements[i].style.backgroundColor = color; } elements = document.getElementById(id).getElementsByClassName(\"Details\"); for (i=0; i<elements.length; i++) { elements[i].setAttribute(\"data-title\", \"-\"); NetworKit_toggleDetails(elements[i]); elements[i].onclick = function (e) { NetworKit_toggleDetails((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"MathValue\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"nan\") { elements[i].parentNode.innerHTML = \"\" } } elements = document.getElementById(id).getElementsByClassName(\"SubCategory\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } elements = document.getElementById(id).getElementsByClassName(\"Category\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } var isFirefox = false; try { isFirefox = typeof InstallTrigger !== \"undefined\"; } catch (e) {} if (!isFirefox) { alert(\"Currently the function\\'s output is only fully supported by Firefox.\"); } } function NetworKit_plotUpdate(source) { var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(source.id + \"_Image\"); image.style.backgroundImage = \"url(\" + data + \")\"; } function NetworKit_showElement(id, show) { var element = document.getElementById(id); element.style.display = (show) ? \"block\" : \"none\"; } function NetworKit_overlayShow(source) { NetworKit_overlayUpdate(source); NetworKit_showElement(\"NetworKit_Overlay\", true); } function NetworKit_overlayUpdate(source) { document.getElementById(\"NetworKit_Overlay_Title\").innerHTML = source.title; var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(\"NetworKit_Overlay_Image\"); image.setAttribute(\"data-id\", source.id); image.style.backgroundImage = \"url(\" + data + \")\"; var link = document.getElementById(\"NetworKit_Overlay_Toolbar_Bottom_Save\"); link.href = data; link.download = source.title + \".svg\"; } function NetworKit_overlayImageShift(delta) { var image = document.getElementById(\"NetworKit_Overlay_Image\"); var source = document.getElementById(image.getAttribute(\"data-id\")); var index = parseInt(source.getAttribute(\"data-image-index\")); var length = parseInt(source.getAttribute(\"data-image-length\")); var index = (index+delta) % length; if (index < 0) { index = length + index; } source.setAttribute(\"data-image-index\", index); NetworKit_overlayUpdate(source); } function NetworKit_toggleDetails(source) { var childs = source.children; var show = false; if (source.getAttribute(\"data-title\") == \"-\") { source.setAttribute(\"data-title\", \"+\"); show = false; } else { source.setAttribute(\"data-title\", \"-\"); show = true; } for (i=0; i<childs.length; i++) { if (show) { childs[i].style.display = \"block\"; } else { childs[i].style.display = \"none\"; } } }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_script');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_style');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('style');\n",
       "\t\t\t\telement.type = 'text/css';\n",
       "\t\t\t\telement.innerHTML = '.NetworKit_Page { font-family: Arial, Helvetica, sans-serif; font-size: 14px; } .NetworKit_Page .Value:before { font-family: Arial, Helvetica, sans-serif; font-size: 1.05em; content: attr(data-title) \":\"; margin-left: -2.5em; padding-right: 0.5em; } .NetworKit_Page .Details .Value:before { display: block; } .NetworKit_Page .Value { font-family: monospace; white-space: pre; padding-left: 2.5em; white-space: -moz-pre-wrap !important; white-space: -pre-wrap; white-space: -o-pre-wrap; white-space: pre-wrap; word-wrap: break-word; tab-size: 4; -moz-tab-size: 4; } .NetworKit_Page .Category { clear: both; padding-left: 1em; margin-bottom: 1.5em; } .NetworKit_Page .Category:before { content: attr(data-title); font-size: 1.75em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory { margin-bottom: 1.5em; padding-left: 1em; } .NetworKit_Page .SubCategory:before { font-size: 1.6em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory[data-title]:before { content: attr(data-title); } .NetworKit_Page .Block { display: block; } .NetworKit_Page .Block:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .Block .Thumbnail_Overview, .NetworKit_Page .Block .Thumbnail_ScatterPlot { width: 260px; float: left; } .NetworKit_Page .Block .Thumbnail_Overview img, .NetworKit_Page .Block .Thumbnail_ScatterPlot img { width: 260px; } .NetworKit_Page .Block .Thumbnail_Overview:before, .NetworKit_Page .Block .Thumbnail_ScatterPlot:before { display: block; text-align: center; font-weight: bold; } .NetworKit_Page .Block .Thumbnail_Overview:before { content: attr(data-title); } .NetworKit_Page .HeatCell { font-family: \"Courier New\", Courier, monospace; cursor: pointer; } .NetworKit_Page .HeatCell, .NetworKit_Page .HeatCellName { display: inline; padding: 0.1em; margin-right: 2px; background-color: #FFFFFF } .NetworKit_Page .HeatCellName { margin-left: 0.25em; } .NetworKit_Page .HeatCell:before { content: attr(data-heat); display: inline-block; color: #000000; width: 4em; text-align: center; } .NetworKit_Page .Measure { clear: both; } .NetworKit_Page .Measure .Details { cursor: pointer; } .NetworKit_Page .Measure .Details:before { content: \"[\" attr(data-title) \"]\"; display: block; } .NetworKit_Page .Measure .Details .Value { border-left: 1px dotted black; margin-left: 0.4em; padding-left: 3.5em; pointer-events: none; } .NetworKit_Page .Measure .Details .Spacer:before { content: \".\"; opacity: 0.0; pointer-events: none; } .NetworKit_Page .Measure .Plot { width: 440px; height: 440px; cursor: pointer; float: left; margin-left: -0.9em; margin-right: 20px; } .NetworKit_Page .Measure .Plot .Image { background-repeat: no-repeat; background-position: center center; background-size: contain; height: 100%; pointer-events: none; } .NetworKit_Page .Measure .Stat { width: 500px; float: left; } .NetworKit_Page .Measure .Stat .Group { padding-left: 1.25em; margin-bottom: 0.75em; } .NetworKit_Page .Measure .Stat .Group .Title { font-size: 1.1em; display: block; margin-bottom: 0.3em; margin-left: -0.75em; border-right-style: dotted; border-right-width: 1px; border-bottom-style: dotted; border-bottom-width: 1px; background-color: #D0D0D0; padding-left: 0.2em; } .NetworKit_Page .Measure .Stat .Group .List { -webkit-column-count: 3; -moz-column-count: 3; column-count: 3; } .NetworKit_Page .Measure .Stat .Group .List .Entry { position: relative; line-height: 1.75em; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:before { position: absolute; left: 0; top: -40px; background-color: #808080; color: #ffffff; height: 30px; line-height: 30px; border-radius: 5px; padding: 0 15px; content: attr(data-tooltip); white-space: nowrap; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:after { position: absolute; left: 15px; top: -10px; border-top: 7px solid #808080; border-left: 7px solid transparent; border-right: 7px solid transparent; content: \"\"; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:after, .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:before { display: block; } .NetworKit_Page .Measure .Stat .Group .List .Entry .MathValue { font-family: \"Courier New\", Courier, monospace; } .NetworKit_Page .Measure:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .PartitionPie { clear: both; } .NetworKit_Page .PartitionPie img { width: 600px; } #NetworKit_Overlay { left: 0px; top: 0px; display: none; position: absolute; width: 100%; height: 100%; background-color: rgba(0,0,0,0.6); z-index: 1000; } #NetworKit_Overlay_Title { position: absolute; color: white; transform: rotate(-90deg); width: 32em; height: 32em; padding-right: 0.5em; padding-top: 0.5em; text-align: right; font-size: 40px; } #NetworKit_Overlay .button { background: white; cursor: pointer; } #NetworKit_Overlay .button:before { size: 13px; display: inline-block; text-align: center; margin-top: 0.5em; margin-bottom: 0.5em; width: 1.5em; height: 1.5em; } #NetworKit_Overlay .icon-close:before { content: \"X\"; } #NetworKit_Overlay .icon-previous:before { content: \"P\"; } #NetworKit_Overlay .icon-next:before { content: \"N\"; } #NetworKit_Overlay .icon-save:before { content: \"S\"; } #NetworKit_Overlay_Toolbar_Top, #NetworKit_Overlay_Toolbar_Bottom { position: absolute; width: 40px; right: 13px; text-align: right; z-index: 1100; } #NetworKit_Overlay_Toolbar_Top { top: 0.5em; } #NetworKit_Overlay_Toolbar_Bottom { Bottom: 0.5em; } #NetworKit_Overlay_ImageContainer { position: absolute; top: 5%; left: 5%; height: 90%; width: 90%; background-repeat: no-repeat; background-position: center center; background-size: contain; } #NetworKit_Overlay_Image { height: 100%; width: 100%; background-repeat: no-repeat; background-position: center center; background-size: contain; }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_style');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_Overlay');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('div');\n",
       "\t\t\t\telement.innerHTML = '<div id=\"NetworKit_Overlay_Toolbar_Top\"><div class=\"button icon-close\" id=\"NetworKit_Overlay_Close\" /></div><div id=\"NetworKit_Overlay_Title\" /> <div id=\"NetworKit_Overlay_ImageContainer\"> <div id=\"NetworKit_Overlay_Image\" /> </div> <div id=\"NetworKit_Overlay_Toolbar_Bottom\"> <div class=\"button icon-previous\" onclick=\"NetworKit_overlayImageShift(-1)\" /> <div class=\"button icon-next\" onclick=\"NetworKit_overlayImageShift(1)\" /> <a id=\"NetworKit_Overlay_Toolbar_Bottom_Save\"><div class=\"button icon-save\" /></a> </div>';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_Overlay');\n",
       "\t\t\t\tdocument.body.appendChild(element);\n",
       "\t\t\t\tdocument.getElementById('NetworKit_Overlay_Close').onclick = function (e) {\n",
       "\t\t\t\t\tdocument.getElementById('NetworKit_Overlay').style.display = 'none';\n",
       "\t\t\t\t}\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t-->\n",
       "\t\t\t</script>\n",
       "\t\t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chromosome 1...\n",
      "Completed processing for chromosome 1\n",
      "\n",
      "Processing chromosome 2...\n",
      "Completed processing for chromosome 2\n",
      "\n",
      "Processing chromosome 3...\n",
      "Completed processing for chromosome 3\n",
      "\n",
      "Processing chromosome 4...\n",
      "Completed processing for chromosome 4\n",
      "\n",
      "Processing chromosome 5...\n",
      "Completed processing for chromosome 5\n",
      "\n",
      "Processing chromosome 6...\n",
      "Completed processing for chromosome 6\n",
      "\n",
      "Processing chromosome 7...\n",
      "Completed processing for chromosome 7\n",
      "\n",
      "Processing chromosome 8...\n",
      "Completed processing for chromosome 8\n",
      "\n",
      "Processing chromosome 9...\n",
      "Completed processing for chromosome 9\n",
      "\n",
      "Processing chromosome 10...\n",
      "Completed processing for chromosome 10\n",
      "\n",
      "Processing chromosome 11...\n",
      "Completed processing for chromosome 11\n",
      "\n",
      "Processing chromosome 12...\n",
      "Completed processing for chromosome 12\n",
      "\n",
      "Processing chromosome 13...\n",
      "Completed processing for chromosome 13\n",
      "\n",
      "Processing chromosome 14...\n",
      "Completed processing for chromosome 14\n",
      "\n",
      "Processing chromosome 15...\n",
      "Completed processing for chromosome 15\n",
      "\n",
      "Processing chromosome 16...\n",
      "Completed processing for chromosome 16\n",
      "\n",
      "Processing chromosome 17...\n",
      "Completed processing for chromosome 17\n",
      "\n",
      "Processing chromosome 18...\n",
      "Completed processing for chromosome 18\n",
      "\n",
      "Processing chromosome 19...\n",
      "Completed processing for chromosome 19\n",
      "\n",
      "Processing chromosome 20...\n",
      "Completed processing for chromosome 20\n",
      "\n",
      "Processing chromosome 22...\n",
      "Completed processing for chromosome 22\n",
      "\n",
      "Processing chromosome 23...\n",
      "Completed processing for chromosome 23\n",
      "\n",
      "Script execution completed.\n",
      "CPU times: total: 1min 58s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import networkit as nk\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load and prepare the data\n",
    "data = pd.read_parquet('gwas_fm_t2d.parquet')\n",
    "\n",
    "# Get unique chromosome numbers\n",
    "chromosomes = data['#chrom'].unique()\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "\n",
    "for chrom in chromosomes:\n",
    "    print(f\"Processing chromosome {chrom}...\")\n",
    "\n",
    "    df = data[data['#chrom'] == chrom]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Create a graph and add nodes\n",
    "    G = nk.Graph(directed=False)\n",
    "    G.addNodes(len(df))\n",
    "\n",
    "    # Store node attributes in a dictionary\n",
    "    attributes = ['pos', 'ref', 'alt', 'mlogp', 'beta', 'sebeta', 'af_alt', 'af_alt_cases', 'prob', 'lead_r2', 'cs_99', 'causal']\n",
    "    node_attributes = {attr: df[attr].tolist() for attr in attributes}\n",
    "\n",
    "    # Get gene columns and create a mapping from gene values to node indices\n",
    "    gene_cols = [f'gene_{i}' for i in range(3)]\n",
    "    melted_df = df.reset_index().melt(id_vars='index', value_vars=gene_cols)\n",
    "    grouped_df = melted_df[melted_df['value'].notnull() & (melted_df['value'] != 0)].groupby('value')['index'].apply(list)\n",
    "    \n",
    "    # Add edges to the graph based on genes\n",
    "    added_edges = set()\n",
    "    for node_indices in grouped_df:\n",
    "        for i, j in combinations(node_indices, 2):\n",
    "            if (i, j) not in added_edges and (j, i) not in added_edges:\n",
    "                G.addEdge(i, j)\n",
    "                added_edges.add((i, j))\n",
    "    \n",
    "    # Filter rows where 'lead_r2' > 0.8\n",
    "    filtered_df = df[df['lead_r2'] > 0.8]\n",
    "    \n",
    "    # Use a single loop instead of nested loops\n",
    "    for i in filtered_df.index:\n",
    "        for j in filtered_df.index:\n",
    "            if i >= j:  # Skip redundant pairs\n",
    "                continue\n",
    "            # Check if both SNPs have the same 'cs_99' value\n",
    "            if df.loc[i, 'cs_99'] == df.loc[j, 'cs_99']:\n",
    "                if (i, j) not in added_edges:\n",
    "                    G.addEdge(i, j)\n",
    "                    added_edges.add((i, j))\n",
    "\n",
    "\n",
    "    # Compute the number of connected components\n",
    "    components = nk.components.ConnectedComponents(G)\n",
    "    components.run()\n",
    "\n",
    "    # Get the component of each node and identify causal nodes\n",
    "    node_to_component = components.getPartition()\n",
    "    causal_node_indices = [i for i, val in enumerate(node_attributes['causal']) if val == 1]\n",
    "\n",
    "    # Identify and print details of components with causal nodes\n",
    "    causal_node_components = {i: node_to_component[i] for i in causal_node_indices}\n",
    "\n",
    "    component_sizes = components.getComponentSizes()\n",
    "    unique_component_ids_and_sizes = {component: component_sizes[component] for component in set(causal_node_components.values())}\n",
    "\n",
    "    # Check for edges between causal nodes in the same component\n",
    "    components_to_causal_nodes = defaultdict(list)\n",
    "    for node, component in causal_node_components.items():\n",
    "        components_to_causal_nodes[component].append(node)\n",
    "\n",
    "    # Create a dictionary to store results of the current chromosome\n",
    "    chrom_results = {\n",
    "        \"chromosome\": chrom,\n",
    "        \"total_nodes\": G.numberOfNodes(),\n",
    "        \"total_edges\": G.numberOfEdges(),\n",
    "        \"connected_components\": components.numberOfComponents(),\n",
    "        \"causal_nodes_count\": len(causal_node_indices),\n",
    "        \"causal_node_details\": causal_node_components,\n",
    "        \"component_details\": unique_component_ids_and_sizes,\n",
    "        \"edge_checks\": []\n",
    "    }\n",
    "    \n",
    "    for component, nodes in components_to_causal_nodes.items():\n",
    "        for u, v in combinations(nodes, 2):\n",
    "            has_edge = G.hasEdge(u, v)\n",
    "            edge_check_details = {\n",
    "                \"component\": component, \n",
    "                \"node_pair\": (u, v), \n",
    "                \"has_edge\": has_edge\n",
    "            }\n",
    "            chrom_results[\"edge_checks\"].append(edge_check_details)\n",
    "\n",
    "    # Add the current chromosome's results to the list\n",
    "    results.append(chrom_results)\n",
    "\n",
    "    print(f\"Completed processing for chromosome {chrom}\\n\")\n",
    "\n",
    "# Create a DataFrame from the list of results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file (or any other format you prefer)\n",
    "results_df.to_csv('chromosome_results_t2d.csv', index=False)\n",
    "\n",
    "print(\"Script execution completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eda84e-0769-4a39-9371-2524a91de343",
   "metadata": {},
   "source": [
    "## Chrom Figs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de38018-65ee-497b-9a81-8a061acbf6d7",
   "metadata": {},
   "source": [
    "### Chrom 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bba99d7-7e95-45dd-b47a-f39582c9d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import networkit as nk\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load and prepare the data\n",
    "data = pd.read_parquet('gwas_fm_t2d.parquet')\n",
    "\n",
    "# Process only chromosome 5\n",
    "chrom = 5\n",
    "\n",
    "df = data[data['#chrom'] == chrom]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "\n",
    "print(f\"Processing chromosome {chrom}...\")\n",
    "\n",
    "# Create a graph and add nodes\n",
    "G = nk.Graph(directed=False)\n",
    "G.addNodes(len(df))\n",
    "\n",
    "# Store node attributes in a dictionary\n",
    "attributes = ['pos', 'ref', 'alt', 'mlogp', 'beta', 'sebeta', 'af_alt', 'af_alt_cases', 'prob', 'lead_r2', 'cs_99', 'causal']\n",
    "node_attributes = {attr: df[attr].tolist() for attr in attributes}\n",
    "\n",
    "# Get gene columns and create a mapping from gene values to node indices\n",
    "gene_cols = [f'gene_{i}' for i in range(22)]\n",
    "melted_df = df.reset_index().melt(id_vars='index', value_vars=gene_cols)\n",
    "grouped_df = melted_df[melted_df['value'].notnull() & (melted_df['value'] != 0)].groupby('value')['index'].apply(list)\n",
    "\n",
    "# Add edges to the graph based on genes\n",
    "added_edges = set()\n",
    "for node_indices in grouped_df:\n",
    "    for i, j in combinations(node_indices, 2):\n",
    "        if (i, j) not in added_edges and (j, i) not in added_edges:\n",
    "            G.addEdge(i, j)\n",
    "            added_edges.add((i, j))\n",
    "\n",
    "# Filter rows where 'lead_r2' > 0.8\n",
    "filtered_df = df[df['lead_r2'] > 0.8]\n",
    "\n",
    "# Use a single loop instead of nested loops\n",
    "for i in filtered_df.index:\n",
    "    for j in filtered_df.index:\n",
    "        if i >= j:  # Skip redundant pairs\n",
    "            continue\n",
    "        # Check if both SNPs have the same 'cs_99' value\n",
    "        if df.loc[i, 'cs_99'] == df.loc[j, 'cs_99']:\n",
    "            if (i, j) not in added_edges:\n",
    "                G.addEdge(i, j)\n",
    "                added_edges.add((i, j))\n",
    "\n",
    "# Compute the number of connected components\n",
    "components = nk.components.ConnectedComponents(G)\n",
    "components.run()\n",
    "\n",
    "# Get the component of each node and identify causal nodes\n",
    "node_to_component = components.getPartition()\n",
    "causal_node_indices = [i for i, val in enumerate(node_attributes['causal']) if val == 1]\n",
    "\n",
    "# Identify and print details of components with causal nodes\n",
    "causal_node_components = {i: node_to_component[i] for i in causal_node_indices}\n",
    "\n",
    "component_sizes = components.getComponentSizes()\n",
    "unique_component_ids_and_sizes = {component: component_sizes[component] for component in set(causal_node_components.values())}\n",
    "\n",
    "# Check for edges between causal nodes in the same component\n",
    "components_to_causal_nodes = defaultdict(list)\n",
    "for node, component in causal_node_components.items():\n",
    "    components_to_causal_nodes[component].append(node)\n",
    "\n",
    "# Create a dictionary to store results of the current chromosome\n",
    "chrom_results = {\n",
    "    \"chromosome\": chrom,\n",
    "    \"total_nodes\": G.numberOfNodes(),\n",
    "    \"total_edges\": G.numberOfEdges(),\n",
    "    \"connected_components\": components.numberOfComponents(),\n",
    "    \"causal_nodes_count\": len(causal_node_indices),\n",
    "    \"causal_node_details\": causal_node_components,\n",
    "    \"component_details\": unique_component_ids_and_sizes,\n",
    "    \"edge_checks\": []\n",
    "}\n",
    "\n",
    "for component, nodes in components_to_causal_nodes.items():\n",
    "    for u, v in combinations(nodes, 2):\n",
    "        has_edge = G.hasEdge(u, v)\n",
    "        edge_check_details = {\n",
    "            \"component\": component, \n",
    "            \"node_pair\": (u, v), \n",
    "            \"has_edge\": has_edge\n",
    "        }\n",
    "        chrom_results[\"edge_checks\"].append(edge_check_details)\n",
    "\n",
    "# Add the current chromosome's results to the list\n",
    "results.append(chrom_results)\n",
    "\n",
    "# Convert the networkit graph to a networkx graph for visualization\n",
    "G_nx = nk.nxadapter.nk2nx(G)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "plt.figure(figsize=(24, 24))\n",
    "\n",
    "# Using spring_layout for faster rendering; adjust as per need.\n",
    "pos = nx.spring_layout(G_nx, iterations=50)  \n",
    "\n",
    "# Extract nodes with causal=1\n",
    "causal_nodes = [index for index, is_causal in enumerate(node_attributes['causal']) if is_causal == 1]\n",
    "\n",
    "# Draw all nodes\n",
    "nx.draw(G_nx, pos, node_size=5, node_color=\"blue\", alpha=0.5, with_labels=False)\n",
    "\n",
    "# Draw only causal=1 nodes on top with bright red color and larger size\n",
    "nx.draw_networkx_nodes(G_nx, pos, nodelist=causal_nodes, node_color=\"red\", node_size=50, alpha=1)\n",
    "\n",
    "plt.title(\"Graph for Chromosome 5\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed0d118-caf4-474e-b06d-7613fb6ddc7c",
   "metadata": {},
   "source": [
    "### Chrom 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d624ac8a-3598-4a2d-b113-742b9eae4396",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import networkit as nk\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load and prepare the data\n",
    "data = pd.read_parquet('gwas_fm_t2d.parquet')\n",
    "\n",
    "# Process only chromosome 3\n",
    "chrom = 3\n",
    "\n",
    "df = data[data['#chrom'] == chrom]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "\n",
    "print(f\"Processing chromosome {chrom}...\")\n",
    "\n",
    "# Create a graph and add nodes\n",
    "G = nk.Graph(directed=False)\n",
    "G.addNodes(len(df))\n",
    "\n",
    "# Store node attributes in a dictionary\n",
    "attributes = ['pos', 'ref', 'alt', 'mlogp', 'beta', 'sebeta', 'af_alt', 'af_alt_cases', 'prob', 'lead_r2', 'cs_99', 'causal']\n",
    "node_attributes = {attr: df[attr].tolist() for attr in attributes}\n",
    "\n",
    "# Get gene columns and create a mapping from gene values to node indices\n",
    "gene_cols = [f'gene_{i}' for i in range(22)]\n",
    "melted_df = df.reset_index().melt(id_vars='index', value_vars=gene_cols)\n",
    "grouped_df = melted_df[melted_df['value'].notnull() & (melted_df['value'] != 0)].groupby('value')['index'].apply(list)\n",
    "\n",
    "# Add edges to the graph based on genes\n",
    "added_edges = set()\n",
    "for node_indices in grouped_df:\n",
    "    for i, j in combinations(node_indices, 2):\n",
    "        if (i, j) not in added_edges and (j, i) not in added_edges:\n",
    "            G.addEdge(i, j)\n",
    "            added_edges.add((i, j))\n",
    "\n",
    "# Filter rows where 'lead_r2' > 0.8\n",
    "filtered_df = df[df['lead_r2'] > 0.8]\n",
    "\n",
    "# Use a single loop instead of nested loops\n",
    "for i in filtered_df.index:\n",
    "    for j in filtered_df.index:\n",
    "        if i >= j:  # Skip redundant pairs\n",
    "            continue\n",
    "        # Check if both SNPs have the same 'cs_99' value\n",
    "        if df.loc[i, 'cs_99'] == df.loc[j, 'cs_99']:\n",
    "            if (i, j) not in added_edges:\n",
    "                G.addEdge(i, j)\n",
    "                added_edges.add((i, j))\n",
    "\n",
    "# Compute the number of connected components\n",
    "components = nk.components.ConnectedComponents(G)\n",
    "components.run()\n",
    "\n",
    "# Get the component of each node and identify causal nodes\n",
    "node_to_component = components.getPartition()\n",
    "causal_node_indices = [i for i, val in enumerate(node_attributes['causal']) if val == 1]\n",
    "\n",
    "# Identify and print details of components with causal nodes\n",
    "causal_node_components = {i: node_to_component[i] for i in causal_node_indices}\n",
    "\n",
    "component_sizes = components.getComponentSizes()\n",
    "unique_component_ids_and_sizes = {component: component_sizes[component] for component in set(causal_node_components.values())}\n",
    "\n",
    "# Check for edges between causal nodes in the same component\n",
    "components_to_causal_nodes = defaultdict(list)\n",
    "for node, component in causal_node_components.items():\n",
    "    components_to_causal_nodes[component].append(node)\n",
    "\n",
    "# Create a dictionary to store results of the current chromosome\n",
    "chrom_results = {\n",
    "    \"chromosome\": chrom,\n",
    "    \"total_nodes\": G.numberOfNodes(),\n",
    "    \"total_edges\": G.numberOfEdges(),\n",
    "    \"connected_components\": components.numberOfComponents(),\n",
    "    \"causal_nodes_count\": len(causal_node_indices),\n",
    "    \"causal_node_details\": causal_node_components,\n",
    "    \"component_details\": unique_component_ids_and_sizes,\n",
    "    \"edge_checks\": []\n",
    "}\n",
    "\n",
    "for component, nodes in components_to_causal_nodes.items():\n",
    "    for u, v in combinations(nodes, 2):\n",
    "        has_edge = G.hasEdge(u, v)\n",
    "        edge_check_details = {\n",
    "            \"component\": component, \n",
    "            \"node_pair\": (u, v), \n",
    "            \"has_edge\": has_edge\n",
    "        }\n",
    "        chrom_results[\"edge_checks\"].append(edge_check_details)\n",
    "\n",
    "# Add the current chromosome's results to the list\n",
    "results.append(chrom_results)\n",
    "\n",
    "# Convert the networkit graph to a networkx graph for visualization\n",
    "G_nx = nk.nxadapter.nk2nx(G)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "plt.figure(figsize=(24, 24))\n",
    "\n",
    "# Using spring_layout for faster rendering; adjust as per need.\n",
    "pos = nx.spring_layout(G_nx, iterations=50)  \n",
    "\n",
    "# Extract nodes with causal=1\n",
    "causal_nodes = [index for index, is_causal in enumerate(node_attributes['causal']) if is_causal == 1]\n",
    "\n",
    "# Draw all nodes\n",
    "nx.draw(G_nx, pos, node_size=5, node_color=\"blue\", alpha=0.5, with_labels=False)\n",
    "\n",
    "# Draw only causal=1 nodes on top with bright red color and larger size\n",
    "nx.draw_networkx_nodes(G_nx, pos, nodelist=causal_nodes, node_color=\"red\", node_size=50, alpha=1)\n",
    "\n",
    "plt.title(\"Graph for Chromosome 3\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2a35a-e4c9-42d4-a05a-20e7a9c8217b",
   "metadata": {},
   "source": [
    "### Chrom 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d9e61-1dcd-4b7c-8ba4-5d5dd8086654",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import networkit as nk\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load and prepare the data\n",
    "data = pd.read_parquet('gwas_fm_t2d.parquet')\n",
    "\n",
    "# Process only chromosome 7\n",
    "chrom = 7\n",
    "\n",
    "df = data[data['#chrom'] == chrom]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "\n",
    "print(f\"Processing chromosome {chrom}...\")\n",
    "\n",
    "# Create a graph and add nodes\n",
    "G = nk.Graph(directed=False)\n",
    "G.addNodes(len(df))\n",
    "\n",
    "# Store node attributes in a dictionary\n",
    "attributes = ['pos', 'ref', 'alt', 'mlogp', 'beta', 'sebeta', 'af_alt', 'af_alt_cases', 'prob', 'lead_r2', 'cs_99', 'causal']\n",
    "node_attributes = {attr: df[attr].tolist() for attr in attributes}\n",
    "\n",
    "# Get gene columns and create a mapping from gene values to node indices\n",
    "gene_cols = [f'gene_{i}' for i in range(22)]\n",
    "melted_df = df.reset_index().melt(id_vars='index', value_vars=gene_cols)\n",
    "grouped_df = melted_df[melted_df['value'].notnull() & (melted_df['value'] != 0)].groupby('value')['index'].apply(list)\n",
    "\n",
    "# Add edges to the graph based on genes\n",
    "added_edges = set()\n",
    "for node_indices in grouped_df:\n",
    "    for i, j in combinations(node_indices, 2):\n",
    "        if (i, j) not in added_edges and (j, i) not in added_edges:\n",
    "            G.addEdge(i, j)\n",
    "            added_edges.add((i, j))\n",
    "\n",
    "# Filter rows where 'lead_r2' > 0.8\n",
    "filtered_df = df[df['lead_r2'] > 0.8]\n",
    "\n",
    "# Use a single loop instead of nested loops\n",
    "for i in filtered_df.index:\n",
    "    for j in filtered_df.index:\n",
    "        if i >= j:  # Skip redundant pairs\n",
    "            continue\n",
    "        # Check if both SNPs have the same 'cs_99' value\n",
    "        if df.loc[i, 'cs_99'] == df.loc[j, 'cs_99']:\n",
    "            if (i, j) not in added_edges:\n",
    "                G.addEdge(i, j)\n",
    "                added_edges.add((i, j))\n",
    "\n",
    "# Compute the number of connected components\n",
    "components = nk.components.ConnectedComponents(G)\n",
    "components.run()\n",
    "\n",
    "# Get the component of each node and identify causal nodes\n",
    "node_to_component = components.getPartition()\n",
    "causal_node_indices = [i for i, val in enumerate(node_attributes['causal']) if val == 1]\n",
    "\n",
    "# Identify and print details of components with causal nodes\n",
    "causal_node_components = {i: node_to_component[i] for i in causal_node_indices}\n",
    "\n",
    "component_sizes = components.getComponentSizes()\n",
    "unique_component_ids_and_sizes = {component: component_sizes[component] for component in set(causal_node_components.values())}\n",
    "\n",
    "# Check for edges between causal nodes in the same component\n",
    "components_to_causal_nodes = defaultdict(list)\n",
    "for node, component in causal_node_components.items():\n",
    "    components_to_causal_nodes[component].append(node)\n",
    "\n",
    "# Create a dictionary to store results of the current chromosome\n",
    "chrom_results = {\n",
    "    \"chromosome\": chrom,\n",
    "    \"total_nodes\": G.numberOfNodes(),\n",
    "    \"total_edges\": G.numberOfEdges(),\n",
    "    \"connected_components\": components.numberOfComponents(),\n",
    "    \"causal_nodes_count\": len(causal_node_indices),\n",
    "    \"causal_node_details\": causal_node_components,\n",
    "    \"component_details\": unique_component_ids_and_sizes,\n",
    "    \"edge_checks\": []\n",
    "}\n",
    "\n",
    "for component, nodes in components_to_causal_nodes.items():\n",
    "    for u, v in combinations(nodes, 2):\n",
    "        has_edge = G.hasEdge(u, v)\n",
    "        edge_check_details = {\n",
    "            \"component\": component, \n",
    "            \"node_pair\": (u, v), \n",
    "            \"has_edge\": has_edge\n",
    "        }\n",
    "        chrom_results[\"edge_checks\"].append(edge_check_details)\n",
    "\n",
    "# Add the current chromosome's results to the list\n",
    "results.append(chrom_results)\n",
    "\n",
    "# Convert the networkit graph to a networkx graph for visualization\n",
    "G_nx = nk.nxadapter.nk2nx(G)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "plt.figure(figsize=(24, 24))\n",
    "\n",
    "# Using spring_layout for faster rendering; adjust as per need.\n",
    "pos = nx.spring_layout(G_nx, iterations=50)  \n",
    "\n",
    "# Extract nodes with causal=1\n",
    "causal_nodes = [index for index, is_causal in enumerate(node_attributes['causal']) if is_causal == 1]\n",
    "\n",
    "# Draw all nodes\n",
    "nx.draw(G_nx, pos, node_size=5, node_color=\"blue\", alpha=0.5, with_labels=False)\n",
    "\n",
    "# Draw only causal=1 nodes on top with bright red color and larger size\n",
    "nx.draw_networkx_nodes(G_nx, pos, nodelist=causal_nodes, node_color=\"red\", node_size=50, alpha=1)\n",
    "\n",
    "plt.title(\"Graph for Chromosome 7\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc5bec-b5ca-4492-868d-c75dab719761",
   "metadata": {},
   "source": [
    "### Chrom 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd16ca4-a2be-408a-95d4-801aececb181",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import networkit as nk\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load and prepare the data\n",
    "data = pd.read_parquet('gwas_fm_t2d.parquet')\n",
    "\n",
    "# Process only chromosome 10\n",
    "chrom = 10\n",
    "\n",
    "df = data[data['#chrom'] == chrom]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "\n",
    "print(f\"Processing chromosome {chrom}...\")\n",
    "\n",
    "# Create a graph and add nodes\n",
    "G = nk.Graph(directed=False)\n",
    "G.addNodes(len(df))\n",
    "\n",
    "# Store node attributes in a dictionary\n",
    "attributes = ['pos', 'ref', 'alt', 'mlogp', 'beta', 'sebeta', 'af_alt', 'af_alt_cases', 'prob', 'lead_r2', 'cs_99', 'causal']\n",
    "node_attributes = {attr: df[attr].tolist() for attr in attributes}\n",
    "\n",
    "# Get gene columns and create a mapping from gene values to node indices\n",
    "gene_cols = [f'gene_{i}' for i in range(22)]\n",
    "melted_df = df.reset_index().melt(id_vars='index', value_vars=gene_cols)\n",
    "grouped_df = melted_df[melted_df['value'].notnull() & (melted_df['value'] != 0)].groupby('value')['index'].apply(list)\n",
    "\n",
    "# Add edges to the graph based on genes\n",
    "added_edges = set()\n",
    "for node_indices in grouped_df:\n",
    "    for i, j in combinations(node_indices, 2):\n",
    "        if (i, j) not in added_edges and (j, i) not in added_edges:\n",
    "            G.addEdge(i, j)\n",
    "            added_edges.add((i, j))\n",
    "\n",
    "# Filter rows where 'lead_r2' > 0.8\n",
    "filtered_df = df[df['lead_r2'] > 0.8]\n",
    "\n",
    "# Use a single loop instead of nested loops\n",
    "for i in filtered_df.index:\n",
    "    for j in filtered_df.index:\n",
    "        if i >= j:  # Skip redundant pairs\n",
    "            continue\n",
    "        # Check if both SNPs have the same 'cs_99' value\n",
    "        if df.loc[i, 'cs_99'] == df.loc[j, 'cs_99']:\n",
    "            if (i, j) not in added_edges:\n",
    "                G.addEdge(i, j)\n",
    "                added_edges.add((i, j))\n",
    "\n",
    "# Compute the number of connected components\n",
    "components = nk.components.ConnectedComponents(G)\n",
    "components.run()\n",
    "\n",
    "# Get the component of each node and identify causal nodes\n",
    "node_to_component = components.getPartition()\n",
    "causal_node_indices = [i for i, val in enumerate(node_attributes['causal']) if val == 1]\n",
    "\n",
    "# Identify and print details of components with causal nodes\n",
    "causal_node_components = {i: node_to_component[i] for i in causal_node_indices}\n",
    "\n",
    "component_sizes = components.getComponentSizes()\n",
    "unique_component_ids_and_sizes = {component: component_sizes[component] for component in set(causal_node_components.values())}\n",
    "\n",
    "# Check for edges between causal nodes in the same component\n",
    "components_to_causal_nodes = defaultdict(list)\n",
    "for node, component in causal_node_components.items():\n",
    "    components_to_causal_nodes[component].append(node)\n",
    "\n",
    "# Create a dictionary to store results of the current chromosome\n",
    "chrom_results = {\n",
    "    \"chromosome\": chrom,\n",
    "    \"total_nodes\": G.numberOfNodes(),\n",
    "    \"total_edges\": G.numberOfEdges(),\n",
    "    \"connected_components\": components.numberOfComponents(),\n",
    "    \"causal_nodes_count\": len(causal_node_indices),\n",
    "    \"causal_node_details\": causal_node_components,\n",
    "    \"component_details\": unique_component_ids_and_sizes,\n",
    "    \"edge_checks\": []\n",
    "}\n",
    "\n",
    "for component, nodes in components_to_causal_nodes.items():\n",
    "    for u, v in combinations(nodes, 2):\n",
    "        has_edge = G.hasEdge(u, v)\n",
    "        edge_check_details = {\n",
    "            \"component\": component, \n",
    "            \"node_pair\": (u, v), \n",
    "            \"has_edge\": has_edge\n",
    "        }\n",
    "        chrom_results[\"edge_checks\"].append(edge_check_details)\n",
    "\n",
    "# Add the current chromosome's results to the list\n",
    "results.append(chrom_results)\n",
    "\n",
    "# Convert the networkit graph to a networkx graph for visualization\n",
    "G_nx = nk.nxadapter.nk2nx(G)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "plt.figure(figsize=(24, 24))\n",
    "\n",
    "# Using spring_layout for faster rendering; adjust as per need.\n",
    "pos = nx.spring_layout(G_nx, iterations=50)  \n",
    "\n",
    "# Extract nodes with causal=1\n",
    "causal_nodes = [index for index, is_causal in enumerate(node_attributes['causal']) if is_causal == 1]\n",
    "\n",
    "# Draw all nodes\n",
    "nx.draw(G_nx, pos, node_size=5, node_color=\"blue\", alpha=0.5, with_labels=False)\n",
    "\n",
    "# Draw only causal=1 nodes on top with bright red color and larger size\n",
    "nx.draw_networkx_nodes(G_nx, pos, nodelist=causal_nodes, node_color=\"red\", node_size=50, alpha=1)\n",
    "\n",
    "plt.title(\"Graph for Chromosome 10\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f074b956-e487-4b8f-a3e0-b15318ac3af8",
   "metadata": {},
   "source": [
    "### Chrom 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1982fc-d537-4fe8-85e6-2ca977b01df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import networkit as nk\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load and prepare the data\n",
    "data = pd.read_parquet('gwas_fm_t2d.parquet')\n",
    "\n",
    "# Process only chromosome 11\n",
    "chrom = 11\n",
    "\n",
    "df = data[data['#chrom'] == chrom]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "\n",
    "print(f\"Processing chromosome {chrom}...\")\n",
    "\n",
    "# Create a graph and add nodes\n",
    "G = nk.Graph(directed=False)\n",
    "G.addNodes(len(df))\n",
    "\n",
    "# Store node attributes in a dictionary\n",
    "attributes = ['pos', 'ref', 'alt', 'mlogp', 'beta', 'sebeta', 'af_alt', 'af_alt_cases', 'prob', 'lead_r2', 'cs_99', 'causal']\n",
    "node_attributes = {attr: df[attr].tolist() for attr in attributes}\n",
    "\n",
    "# Get gene columns and create a mapping from gene values to node indices\n",
    "gene_cols = [f'gene_{i}' for i in range(22)]\n",
    "melted_df = df.reset_index().melt(id_vars='index', value_vars=gene_cols)\n",
    "grouped_df = melted_df[melted_df['value'].notnull() & (melted_df['value'] != 0)].groupby('value')['index'].apply(list)\n",
    "\n",
    "# Add edges to the graph based on genes\n",
    "added_edges = set()\n",
    "for node_indices in grouped_df:\n",
    "    for i, j in combinations(node_indices, 2):\n",
    "        if (i, j) not in added_edges and (j, i) not in added_edges:\n",
    "            G.addEdge(i, j)\n",
    "            added_edges.add((i, j))\n",
    "\n",
    "# Filter rows where 'lead_r2' > 0.8\n",
    "filtered_df = df[df['lead_r2'] > 0.8]\n",
    "\n",
    "# Use a single loop instead of nested loops\n",
    "for i in filtered_df.index:\n",
    "    for j in filtered_df.index:\n",
    "        if i >= j:  # Skip redundant pairs\n",
    "            continue\n",
    "        # Check if both SNPs have the same 'cs_99' value\n",
    "        if df.loc[i, 'cs_99'] == df.loc[j, 'cs_99']:\n",
    "            if (i, j) not in added_edges:\n",
    "                G.addEdge(i, j)\n",
    "                added_edges.add((i, j))\n",
    "\n",
    "# Compute the number of connected components\n",
    "components = nk.components.ConnectedComponents(G)\n",
    "components.run()\n",
    "\n",
    "# Get the component of each node and identify causal nodes\n",
    "node_to_component = components.getPartition()\n",
    "causal_node_indices = [i for i, val in enumerate(node_attributes['causal']) if val == 1]\n",
    "\n",
    "# Identify and print details of components with causal nodes\n",
    "causal_node_components = {i: node_to_component[i] for i in causal_node_indices}\n",
    "\n",
    "component_sizes = components.getComponentSizes()\n",
    "unique_component_ids_and_sizes = {component: component_sizes[component] for component in set(causal_node_components.values())}\n",
    "\n",
    "# Check for edges between causal nodes in the same component\n",
    "components_to_causal_nodes = defaultdict(list)\n",
    "for node, component in causal_node_components.items():\n",
    "    components_to_causal_nodes[component].append(node)\n",
    "\n",
    "# Create a dictionary to store results of the current chromosome\n",
    "chrom_results = {\n",
    "    \"chromosome\": chrom,\n",
    "    \"total_nodes\": G.numberOfNodes(),\n",
    "    \"total_edges\": G.numberOfEdges(),\n",
    "    \"connected_components\": components.numberOfComponents(),\n",
    "    \"causal_nodes_count\": len(causal_node_indices),\n",
    "    \"causal_node_details\": causal_node_components,\n",
    "    \"component_details\": unique_component_ids_and_sizes,\n",
    "    \"edge_checks\": []\n",
    "}\n",
    "\n",
    "for component, nodes in components_to_causal_nodes.items():\n",
    "    for u, v in combinations(nodes, 2):\n",
    "        has_edge = G.hasEdge(u, v)\n",
    "        edge_check_details = {\n",
    "            \"component\": component, \n",
    "            \"node_pair\": (u, v), \n",
    "            \"has_edge\": has_edge\n",
    "        }\n",
    "        chrom_results[\"edge_checks\"].append(edge_check_details)\n",
    "\n",
    "# Add the current chromosome's results to the list\n",
    "results.append(chrom_results)\n",
    "\n",
    "# Convert the networkit graph to a networkx graph for visualization\n",
    "G_nx = nk.nxadapter.nk2nx(G)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "plt.figure(figsize=(24, 24))\n",
    "\n",
    "# Using spring_layout for faster rendering; adjust as per need.\n",
    "pos = nx.spring_layout(G_nx, iterations=50)  \n",
    "\n",
    "# Extract nodes with causal=1\n",
    "causal_nodes = [index for index, is_causal in enumerate(node_attributes['causal']) if is_causal == 1]\n",
    "\n",
    "# Draw all nodes\n",
    "nx.draw(G_nx, pos, node_size=5, node_color=\"blue\", alpha=0.5, with_labels=False)\n",
    "\n",
    "# Draw only causal=1 nodes on top with bright red color and larger size\n",
    "nx.draw_networkx_nodes(G_nx, pos, nodelist=causal_nodes, node_color=\"red\", node_size=50, alpha=1)\n",
    "\n",
    "plt.title(\"Graph for Chromosome 11\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
